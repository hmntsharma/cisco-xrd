{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cisco XRd and XRD-Tools After struggling to instantiate an XRd control-plane container for a couple of days, I stumbled upon the ios-xr/xrd-tools github repository and it was very easy from there onwards. Here is a summary of observations after using it for a few hours. I tested only the sample topologies provided with the ios-xr/xrd-tools repository Observations: XRd is IOS-XR, so no need to ellaborate I can get used to the xr-compose script, with docker-compose.xr.yml for creating topologies I wish the image already had a username/password set I will try to customize the image and test the original topologies with it Update: Another layer to the exisitng image did not work but if you simply update the startup-config file with the credentials, it works. Tested with the simple-bgp topology Added the following creds, username: cisco, password: ciscoxrd, deployed the lab and the creds worked username cisco group root-lr group cisco-support secret 10 $6$qtiDT/ivnLyw3T/.$JlOj2V4BOGwTJgVvl6AgodCcE6QBYHF6nyXF3ySQiEmKFti5/51Bq42Om5XVd1HuSoSr0F.illObQIzqwcrdR. ! The docker attach --detach-keys=ctrl-\\\\ is good enough for me to attach and detach the containers Thinking out loud, perhaps an ssh server in the custom image would work right out of the box on the mgmt ip, there wouldn't be any need for attach Update: Likewise, simply add ssh server v2 in the startup-config file and ssh also works with the username/password saved above. The ip addresses of the nodes can be found by inspecting the docket network for the mgmt bridge, defined in the docker-compose.yml file lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker network inspect simple-bgp_mgmt | grep -i -E \"name|ipv4\" \"Name\": \"simple-bgp_mgmt\", \"Name\": \"xr-2\", \"IPv4Address\": \"172.30.0.2/24\", \"Name\": \"xr-1\", \"IPv4Address\": \"172.30.0.3/24\", lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ ssh -l cisco 172.30.0.3 (cisco@172.30.0.3) Password: Last login: Sun Aug 21 00:20:58 2022 from 172.30.0.1 RP/0/RP0/CPU0:ios#exit Connection to 172.30.0.3 closed. lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ XRD-Tools uses, only docker(docker-compose) data-plane infrastructure to deploy the topology, which is why there is a docker bridge network for each segment of the topology, which is different from another tool containerlab, which uses docker and base linux both, no complaints, just an observation It would be a quick and easy way to test topologies, automated with netconf and grpc This is just the beginning and it is a step in the right direction!","title":"Introduction"},{"location":"#cisco-xrd-and-xrd-tools","text":"After struggling to instantiate an XRd control-plane container for a couple of days, I stumbled upon the ios-xr/xrd-tools github repository and it was very easy from there onwards. Here is a summary of observations after using it for a few hours. I tested only the sample topologies provided with the ios-xr/xrd-tools repository","title":"Cisco XRd and XRD-Tools"},{"location":"#observations","text":"XRd is IOS-XR, so no need to ellaborate I can get used to the xr-compose script, with docker-compose.xr.yml for creating topologies I wish the image already had a username/password set I will try to customize the image and test the original topologies with it Update: Another layer to the exisitng image did not work but if you simply update the startup-config file with the credentials, it works. Tested with the simple-bgp topology Added the following creds, username: cisco, password: ciscoxrd, deployed the lab and the creds worked username cisco group root-lr group cisco-support secret 10 $6$qtiDT/ivnLyw3T/.$JlOj2V4BOGwTJgVvl6AgodCcE6QBYHF6nyXF3ySQiEmKFti5/51Bq42Om5XVd1HuSoSr0F.illObQIzqwcrdR. ! The docker attach --detach-keys=ctrl-\\\\ is good enough for me to attach and detach the containers Thinking out loud, perhaps an ssh server in the custom image would work right out of the box on the mgmt ip, there wouldn't be any need for attach Update: Likewise, simply add ssh server v2 in the startup-config file and ssh also works with the username/password saved above. The ip addresses of the nodes can be found by inspecting the docket network for the mgmt bridge, defined in the docker-compose.yml file lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker network inspect simple-bgp_mgmt | grep -i -E \"name|ipv4\" \"Name\": \"simple-bgp_mgmt\", \"Name\": \"xr-2\", \"IPv4Address\": \"172.30.0.2/24\", \"Name\": \"xr-1\", \"IPv4Address\": \"172.30.0.3/24\", lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ ssh -l cisco 172.30.0.3 (cisco@172.30.0.3) Password: Last login: Sun Aug 21 00:20:58 2022 from 172.30.0.1 RP/0/RP0/CPU0:ios#exit Connection to 172.30.0.3 closed. lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ XRD-Tools uses, only docker(docker-compose) data-plane infrastructure to deploy the topology, which is why there is a docker bridge network for each segment of the topology, which is different from another tool containerlab, which uses docker and base linux both, no complaints, just an observation It would be a quick and easy way to test topologies, automated with netconf and grpc This is just the beginning and it is a step in the right direction!","title":"Observations:"},{"location":"base_setup/","text":"Infrastructure for Cisco XRd with XRD-Tools Exploring Cisco XRd 7.7.1 (Control-Plane) with the help of ios-xr/xrd-tools in Ubuntu 22.04.1 running in EVE-NG The vRouter image is out of the scope of this document. Setup Ubuntu 22.04.1 [16 vcpu/32GB RAM] Download the Cisco XRd image from the Cisco support portal and upload(e.g. scp) it to the vm. The first public release version is 7.7.1 Note: A Cisco support contract is required to download the image from the official website, in case of any issue, please contact your Cisco account representative. Note: The docker image is inside the archive Install Docker lab@xrdlab:~$ curl -fsSL https://get.docker.com -o get-docker.sh lab@xrdlab:~$ sudo sh get-docker.sh Install Docker-Compose sudo apt install docker-compose Install the Cisco XRd Docker container lab@xrdlab:~/xrd-control-plane$ sudo docker load -i xrd-control-plane-container-x64.dockerv1.tgz a42828b8fe58: Loading layer [==================================================>] 1.179GB/1.179GB Loaded image: localhost/ios-xr:7.7.1 lab@xrdlab:~/xrd-control-plane$ sudo docker images REPOSITORY TAG IMAGE ID CREATED SIZE localhost/ios-xr 7.7.1 dd8d741e50b2 3 weeks ago 1.15GB lab@xrdlab:~/xrd-control-plane$ Clone the XRD-Tools repository lab@xrdlab:~/github$ sudo git clone https://github.com/ios-xr/xrd-tools.git Cloning into 'xrd-tools'... remote: Enumerating objects: 69, done. remote: Counting objects: 100% (69/69), done. remote: Compressing objects: 100% (43/43), done. remote: Total 69 (delta 27), reused 61 (delta 24), pack-reused 0 Receiving objects: 100% (69/69), 84.39 KiB | 3.25 MiB/s, done. Resolving deltas: 100% (27/27), done. lab@xrdlab:~/github$ Host-Check As per the xrd-tools repo, first check whether the host vm is ready to run the XRd or not lab@xrdlab:~/github/xrd-tools/scripts$ sudo ./host-check ============================== Platform checks ============================== base checks ----------------------- PASS -- CPU architecture (x86_64) PASS -- CPU cores (16) PASS -- Kernel version (5.15) PASS -- Base kernel modules Installed module(s): dummy, nf_tables FAIL -- Cgroups version Cgroups version 2 is in use, but this is not supported by XRd. Please use cgroups version 1. SKIP -- systemd mounts Skipped due to failed checks: Cgroups version FAIL -- Inotify max user instances The kernel parameter fs.inotify.max_user_instances is set to 128 but should be at least 4000 (sufficient for a single instance) - the recommended value is 64000. This can be addressed by adding 'fs.inotify.max_user_instances=64000' to /etc/sysctl.conf or in a dedicated conf file under /etc/sysctl.d/. For a temporary fix, run: sysctl -w fs.inotify.max_user_instances=64000 PASS -- Inotify max user watches 249593 - this is expected to be sufficient for 62 XRd instance(s). INFO -- Core pattern (core files managed by the host) PASS -- ASLR (full randomization) INFO -- Linux Security Modules AppArmor is enabled. XRd is currently unable to run with the default docker profile, but can be run with '--security-opt apparmor=unconfined' or equivalent. xrd-control-plane checks ----------------------- PASS -- RAM Available RAM is 30.6 GiB. This is estimated to be sufficient for 15 XRd instance(s), although memory usage depends on the running configuration. Note that any swap that may be available is not included. xrd-vrouter checks ----------------------- FAIL -- CPU extensions Missing CPU extension(s): sse4_1, sse4_2, ssse3 Please install the missing extension(s). PASS -- RAM Available RAM is 30.6 GiB. This is estimated to be sufficient for 6 XRd instance(s), although memory usage depends on the running configuration. Note that any swap that may be available is not included. FAIL -- Hugepages Hugepages are not enabled. These are required for XRd to function correctly. To enable hugepages, see the instructions at: https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt. PASS -- Interface kernel driver (vfio-pci loaded) FAIL -- IOMMU The kernel module vfio-pci cannot be used, as IOMMU is not enabled. IOMMU is recommended for security when using the vfio-pci kernel driver. PASS -- Shared memory pages max size (17179869184.0 GiB) ============================== Extra checks ============================== docker checks ----------------------- PASS -- Docker client (version 20.10.17) PASS -- Docker daemon (running, version 20.10.17) PASS -- Docker supports d_type xr-compose checks ----------------------- FAIL -- docker-compose Docker Compose not found (checked with 'docker-compose --version'). Launching XRd topologies with xr-compose requires docker-compose. See installation instructions at https://docs.docker.com/compose/install/. PASS -- PyYAML (installed) FAIL -- Bridge iptables For xr-compose to be able to use Docker bridges, bridge IP tables must be disabled. Note that there may be security considerations associated with doing so. Bridge IP tables can be disabled by setting the kernel parameters net.bridge.bridge-nf-call-iptables and net.bridge.bridge-nf-call-ip6tables to 0. These can be modified by adding 'net.bridge.bridge-nf-call-iptables=0' and 'net.bridge.bridge-nf-call-ip6tables=0' to /etc/sysctl.conf or in a dedicated conf file under /etc/sysctl.d/. For a temporary fix, run: sysctl -w net.bridge.bridge-nf-call-iptables=0 sysctl -w net.bridge.bridge-nf-call-ip6tables=0 ================================================================== !! Host NOT set up correctly for any XR platforms !! ------------------------------------------------------------------ Extra checks passed: docker Extra checks failed: xr-compose ================================================================== lab@xrdlab:~/github/xrd-tools/scripts$ Fix as per the above output Cgroups to v1, thanks to this post Update the file /etc/default/grub with GRUB_CMDLINE_LINUX_DEFAULT=\"systemd.unified_cgroup_hierarchy=false\" Update grub with sudo update-grub lab@xrdlab:~$ sudo update-grub Sourcing file `/etc/default/grub' Sourcing file `/etc/default/grub.d/init-select.cfg' Generating grub configuration file ... Found linux image: /boot/vmlinuz-5.15.0-46-generic Found initrd image: /boot/initrd.img-5.15.0-46-generic Warning: os-prober will not be executed to detect other bootable partitions. Systems on them will not be added to the GRUB boot configuration. Check GRUB_DISABLE_OS_PROBER documentation entry. done lab@xrdlab:~$ Reboot the vm sudo reboot now Increasing the max user instance echo 'fs.inotify.max_user_instances=249593' >> /etc/sysctl.conf Disable Bridge iptables, thanks to this post , the change is persitent echo 'br_netfilter' >> /etc/modules echo 'net.bridge.bridge-nf-call-iptables=1' >> /etc/sysctl.conf echo 'net.bridge.bridge-nf-call-ip6tables=1' >> /etc/sysctl.conf To update the missing CPU extensions, stop the vm and then add -cpu qemu64,+ssse3,+sse4.1,+sse4.2 in QEMU Custom options of the image in EVE-NG, but it is not applicable for the control-plane image. Host-Check again lab@xrdlab:~/github/xrd-tools/scripts$ sudo ./host-check ============================== Platform checks ============================== base checks ----------------------- PASS -- CPU architecture (x86_64) PASS -- CPU cores (16) PASS -- Kernel version (5.15) PASS -- Base kernel modules Installed module(s): dummy, nf_tables PASS -- Cgroups version (v1) PASS -- systemd mounts /sys/fs/cgroup and /sys/fs/cgroup/systemd mounted correctly. PASS -- Inotify max user instances 249593 - this is expected to be sufficient for 62 XRd instance(s). PASS -- Inotify max user watches 249593 - this is expected to be sufficient for 62 XRd instance(s). INFO -- Core pattern (core files managed by the host) PASS -- ASLR (full randomization) INFO -- Linux Security Modules AppArmor is enabled. XRd is currently unable to run with the default docker profile, but can be run with '--security-opt apparmor=unconfined' or equivalent. xrd-control-plane checks ----------------------- PASS -- RAM Available RAM is 30.7 GiB. This is estimated to be sufficient for 15 XRd instance(s), although memory usage depends on the running configuration. Note that any swap that may be available is not included. xrd-vrouter checks ----------------------- PASS -- CPU extensions (sse4_1, sse4_2, ssse3) PASS -- RAM Available RAM is 30.7 GiB. This is estimated to be sufficient for 6 XRd instance(s), although memory usage depends on the running configuration. Note that any swap that may be available is not included. FAIL -- Hugepages Hugepages are not enabled. These are required for XRd to function correctly. To enable hugepages, see the instructions at: https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt. PASS -- Interface kernel driver (vfio-pci loaded) FAIL -- IOMMU The kernel module vfio-pci cannot be used, as IOMMU is not enabled. IOMMU is recommended for security when using the vfio-pci kernel driver. PASS -- Shared memory pages max size (17179869184.0 GiB) ============================== Extra checks ============================== docker checks ----------------------- PASS -- Docker client (version 20.10.17) PASS -- Docker daemon (running, version 20.10.17) PASS -- Docker supports d_type xr-compose checks ----------------------- PASS -- docker-compose (version 1.29.2) PASS -- PyYAML (installed) PASS -- Bridge iptables (disabled) ================================================================== XR platforms supported: xrd-control-plane XR platforms NOT supported: xrd-vrouter ------------------------------------------------------------------ Extra checks passed: docker, xr-compose ================================================================== lab@xrdlab:~/github/xrd-tools/scripts$ The checks passed and the xrd-control-plane platform is now supported Launch XRd Run the launch-xrd script as below to run a container from the installed image lab@xrdlab:~/github/xrd-tools/scripts$ sudo ./launch-xrd localhost/ios-xr:7.7.1 systemd 230 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP -LIBCRYPTSETUP -GCRYPT -GNUTLS +ACL +XZ -LZ4 -SECCOMP +BLKID -ELFUTILS +KMOD -IDN) Detected virtualization docker. Detected architecture x86-64. Welcome to Cisco XR (Base Distro SELinux and CGL) 9.0.0.26! Set hostname to <2382f3358d2c>. Initializing machine ID from random generator. [ OK ] Listening on Journal Socket. [ OK ] Created slice User and Session Slice. [ OK ] Reached target Paths. [ OK ] Reached target Swap. [ OK ] Reached target Remote File Systems. [ OK ] Created slice System Slice. Starting Remount Root and Kernel File Systems... Mounting Huge Pages File System... [ OK ] Reached target Slices. Mounting FUSE Control File System... Mounting Temporary Directory... [ OK ] Listening on Journal Socket (/dev/log). [ OK ] Listening on Syslog Socket. Starting Journal Service... [ OK ] Mounted Huge Pages File System. [ OK ] Mounted FUSE Control File System. [ OK ] Mounted Temporary Directory. [ OK ] Started Remount Root and Kernel File Systems. Starting Rebuild Hardware Database... Starting Load/Save Random Seed... Starting Create System Users... Starting Copy selected logs to var/log/old directories... Starting Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling... [ OK ] Started Load/Save Random Seed. [ OK ] Started Create System Users. [ OK ] Started Journal Service. Starting Flush Journal to Persistent Storage... [ OK ] Started Flush Journal to Persistent Storage. [ OK ] Started Copy selected logs to var/log/old directories. [ OK ] Started Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling. [ OK ] Reached target Local File Systems (Pre). Mounting /var/volatile... Mounting /mnt... [ OK ] Mounted /var/volatile. [ OK ] Mounted /mnt. [ OK ] Reached target Local File Systems. Starting Rebuild Journal Catalog... Starting Rebuild Dynamic Linker Cache... Starting Create Volatile Files and Directories... [ OK ] Started Rebuild Journal Catalog. [ OK ] Started Create Volatile Files and Directories. Starting Update UTMP about System Boot/Shutdown... [ OK ] Started Update UTMP about System Boot/Shutdown. [ OK ] Started Rebuild Hardware Database. [ OK ] Started Rebuild Dynamic Linker Cache. Starting Update is Completed... [ OK ] Started Update is Completed. [ OK ] Reached target System Initialization. [ OK ] Started Daily Cleanup of Temporary Directories. [ OK ] Reached target Timers. [ OK ] Listening on D-Bus System Message Bus Socket. [ OK ] Reached target Sockets. [ OK ] Reached target Basic System. Starting Resets System Activity Logs... [ OK ] Started IOS-XR XRd Core Watcher. [ OK ] Started Periodic Command Scheduler. [ OK ] Started Job spooling tools. Starting sysklogd Kernel Logging Service... Starting OpenSSH Key Generation... [ OK ] Started Service for factory reset. Starting IOS-XR Setup Non-Root related tasks... Starting System Logging Service... [ OK ] Started D-Bus System Message Bus. [ OK ] Reached target Network. Starting Permit User Sessions... Starting Xinetd A Powerful Replacement For Inetd... Starting /etc/rc.local Compatibility... [ OK ] Started Resets System Activity Logs. [ OK ] Started Permit User Sessions. [ OK ] Started /etc/rc.local Compatibility. [ OK ] Started Xinetd A Powerful Replacement For Inetd. [ OK ] Reached target Login Prompts. [ OK ] Reached target Multi-User System. Starting Update UTMP about System Runlevel Changes... [ OK ] Started Update UTMP about System Runlevel Changes. [ OK ] Started IOS-XR Setup Non-Root related tasks. [ OK ] Started OpenSSH Key Generation. Starting IOS-XR ISO Installation... [ OK ] Started System Logging Service. [ OK ] Started sysklogd Kernel Logging Service. [ 667.401907] xrnginstall[361]: 2022 Aug 20 18:41:13.106 UTC: Setting up dumper and build info files [ 667.529228] xrnginstall[361]: 2022 Aug 20 18:41:13.232 UTC: XR Lineup: r77x.lu%EFR-00000436820 [ 667.536537] xrnginstall[361]: 2022 Aug 20 18:41:13.240 UTC: XR Version: 7.7.1 [ 667.548415] xrnginstall[361]: 2022 Aug 20 18:41:13.252 UTC: Completed set up of dumper and build info files [ 667.557122] xrnginstall[361]: 2022 Aug 20 18:41:13.261 UTC: Preparing IOS-XR (first boot) [ 667.724285] xrnginstall[361]: 2022 Aug 20 18:41:13.427 UTC: Checking if rollback cleanup is required [ 667.733597] xrnginstall[361]: 2022 Aug 20 18:41:13.436 UTC: Finished rollback cleanup stage [ 667.740465] xrnginstall[361]: 2022 Aug 20 18:41:13.443 UTC: Single node: starting XR [ 667.757563] xrnginstall[361]: 2022 Aug 20 18:41:13.461 UTC: xrnginstall completed successfully [ OK ] Started IOS-XR ISO Installation. Starting IOS-XR XRd... [ OK ] Started Cisco Directory Services. [ OK ] Started IOS-XR XRd. Starting IOS-XR Reaperd and Process Manager... [ OK ] Started IOS-XR Reaperd and Process Manager. [ OK ] Reached target XR installation and startup. ios con0/RP0/CPU0 is now available Press RETURN to get started. This product contains cryptographic features and is subject to United States and local country laws governing import, export, transfer and use. Delivery of Cisco cryptographic products does not imply third-party authority to import, export, distribute or use encryption. Importers, exporters, distributors and users are responsible for compliance with U.S. and local country laws. By using this product you agree to comply with applicable laws and regulations. If you are unable to comply with U.S. and local laws, return this product immediately. A summary of U.S. laws governing Cisco cryptographic products may be found at: http://www.cisco.com/wwl/export/crypto/tool/stqrg.html If you require further assistance please contact us by sending email to export@cisco.com. RP/0/RP0/CPU0:Aug 20 18:41:24.932 UTC: pyztp2[252]: %INFRA-ZTP-4-EXITED : ZTP exited !!!!!!!!!!!!!!!!!!!! NO root-system username is configured. Need to configure root-system username. !!!!!!!!!!!!!!!!!!!! --- Administrative User Dialog --- Enter root-system username: RP/0/RP0/CPU0:Aug 20 18:41:28.381 UTC: smartlicserver[266]: %LICENSE-SMART_LIC-3-COMM_FAILED : Communications failure with the Cisco Smart Software Manager (CSSM) : Communications init failure co % Entry must not be null. Enter root-system username: cisco Enter secret: Enter secret again: Use the 'configure' command to modify this configuration. User Access Verification Username: cisco Password: RP/0/RP0/CPU0:ios#show platform Sat Aug 20 18:41:45.892 UTC Node Type State Config state -------------------------------------------------------------------------------- 0/RP0/CPU0 XRd-CP-C-01(Active) IOS XR RUN NSHUT RP/0/RP0/CPU0:ios#show version RP/0/RP0/CPU0:ios# Sat Aug 20 18:41:48.353 UTC Cisco IOS XR Software, Version 7.7.1 LNT Copyright (c) 2013-2022 by Cisco Systems, Inc. Build Information: Built By : ingunawa Built On : Mon Jul 25 06:07:25 UTC 2022 Build Host : iox-lnx-121 Workspace : /auto/srcarchive12/prod/7.7.1/xrd-control-plane/ws Version : 7.7.1 Label : 7.7.1 cisco XRd Control Plane cisco XRd-CP-C-01 processor with 32GB of memory ios uptime is 0 minutes XRd Control Plane Container RP/0/RP0/CPU0:ios#sh int brief Sat Aug 20 18:41:56.784 UTC Intf Intf LineP Encap MTU BW Name State State Type (byte) (Kbps) -------------------------------------------------------------------------------- Nu0 up up Null 1500 0 Mg0/RP0/CPU0/0 admin-down admin-down ARPA 1514 1000000 RP/0/RP0/CPU0:ios# I couldn't get out of the docker container, so I had to stop the container by opening another terminal session to the vm. It works! Thank You!","title":"Setup"},{"location":"base_setup/#infrastructure-for-cisco-xrd-with-xrd-tools","text":"Exploring Cisco XRd 7.7.1 (Control-Plane) with the help of ios-xr/xrd-tools in Ubuntu 22.04.1 running in EVE-NG The vRouter image is out of the scope of this document.","title":"Infrastructure for Cisco XRd with XRD-Tools"},{"location":"base_setup/#setup","text":"Ubuntu 22.04.1 [16 vcpu/32GB RAM] Download the Cisco XRd image from the Cisco support portal and upload(e.g. scp) it to the vm. The first public release version is 7.7.1 Note: A Cisco support contract is required to download the image from the official website, in case of any issue, please contact your Cisco account representative. Note: The docker image is inside the archive Install Docker lab@xrdlab:~$ curl -fsSL https://get.docker.com -o get-docker.sh lab@xrdlab:~$ sudo sh get-docker.sh Install Docker-Compose sudo apt install docker-compose Install the Cisco XRd Docker container lab@xrdlab:~/xrd-control-plane$ sudo docker load -i xrd-control-plane-container-x64.dockerv1.tgz a42828b8fe58: Loading layer [==================================================>] 1.179GB/1.179GB Loaded image: localhost/ios-xr:7.7.1 lab@xrdlab:~/xrd-control-plane$ sudo docker images REPOSITORY TAG IMAGE ID CREATED SIZE localhost/ios-xr 7.7.1 dd8d741e50b2 3 weeks ago 1.15GB lab@xrdlab:~/xrd-control-plane$","title":"Setup"},{"location":"base_setup/#clone-the-xrd-tools-repository","text":"lab@xrdlab:~/github$ sudo git clone https://github.com/ios-xr/xrd-tools.git Cloning into 'xrd-tools'... remote: Enumerating objects: 69, done. remote: Counting objects: 100% (69/69), done. remote: Compressing objects: 100% (43/43), done. remote: Total 69 (delta 27), reused 61 (delta 24), pack-reused 0 Receiving objects: 100% (69/69), 84.39 KiB | 3.25 MiB/s, done. Resolving deltas: 100% (27/27), done. lab@xrdlab:~/github$","title":"Clone the XRD-Tools repository"},{"location":"base_setup/#host-check","text":"As per the xrd-tools repo, first check whether the host vm is ready to run the XRd or not lab@xrdlab:~/github/xrd-tools/scripts$ sudo ./host-check ============================== Platform checks ============================== base checks ----------------------- PASS -- CPU architecture (x86_64) PASS -- CPU cores (16) PASS -- Kernel version (5.15) PASS -- Base kernel modules Installed module(s): dummy, nf_tables FAIL -- Cgroups version Cgroups version 2 is in use, but this is not supported by XRd. Please use cgroups version 1. SKIP -- systemd mounts Skipped due to failed checks: Cgroups version FAIL -- Inotify max user instances The kernel parameter fs.inotify.max_user_instances is set to 128 but should be at least 4000 (sufficient for a single instance) - the recommended value is 64000. This can be addressed by adding 'fs.inotify.max_user_instances=64000' to /etc/sysctl.conf or in a dedicated conf file under /etc/sysctl.d/. For a temporary fix, run: sysctl -w fs.inotify.max_user_instances=64000 PASS -- Inotify max user watches 249593 - this is expected to be sufficient for 62 XRd instance(s). INFO -- Core pattern (core files managed by the host) PASS -- ASLR (full randomization) INFO -- Linux Security Modules AppArmor is enabled. XRd is currently unable to run with the default docker profile, but can be run with '--security-opt apparmor=unconfined' or equivalent. xrd-control-plane checks ----------------------- PASS -- RAM Available RAM is 30.6 GiB. This is estimated to be sufficient for 15 XRd instance(s), although memory usage depends on the running configuration. Note that any swap that may be available is not included. xrd-vrouter checks ----------------------- FAIL -- CPU extensions Missing CPU extension(s): sse4_1, sse4_2, ssse3 Please install the missing extension(s). PASS -- RAM Available RAM is 30.6 GiB. This is estimated to be sufficient for 6 XRd instance(s), although memory usage depends on the running configuration. Note that any swap that may be available is not included. FAIL -- Hugepages Hugepages are not enabled. These are required for XRd to function correctly. To enable hugepages, see the instructions at: https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt. PASS -- Interface kernel driver (vfio-pci loaded) FAIL -- IOMMU The kernel module vfio-pci cannot be used, as IOMMU is not enabled. IOMMU is recommended for security when using the vfio-pci kernel driver. PASS -- Shared memory pages max size (17179869184.0 GiB) ============================== Extra checks ============================== docker checks ----------------------- PASS -- Docker client (version 20.10.17) PASS -- Docker daemon (running, version 20.10.17) PASS -- Docker supports d_type xr-compose checks ----------------------- FAIL -- docker-compose Docker Compose not found (checked with 'docker-compose --version'). Launching XRd topologies with xr-compose requires docker-compose. See installation instructions at https://docs.docker.com/compose/install/. PASS -- PyYAML (installed) FAIL -- Bridge iptables For xr-compose to be able to use Docker bridges, bridge IP tables must be disabled. Note that there may be security considerations associated with doing so. Bridge IP tables can be disabled by setting the kernel parameters net.bridge.bridge-nf-call-iptables and net.bridge.bridge-nf-call-ip6tables to 0. These can be modified by adding 'net.bridge.bridge-nf-call-iptables=0' and 'net.bridge.bridge-nf-call-ip6tables=0' to /etc/sysctl.conf or in a dedicated conf file under /etc/sysctl.d/. For a temporary fix, run: sysctl -w net.bridge.bridge-nf-call-iptables=0 sysctl -w net.bridge.bridge-nf-call-ip6tables=0 ================================================================== !! Host NOT set up correctly for any XR platforms !! ------------------------------------------------------------------ Extra checks passed: docker Extra checks failed: xr-compose ================================================================== lab@xrdlab:~/github/xrd-tools/scripts$","title":"Host-Check"},{"location":"base_setup/#fix-as-per-the-above-output","text":"Cgroups to v1, thanks to this post Update the file /etc/default/grub with GRUB_CMDLINE_LINUX_DEFAULT=\"systemd.unified_cgroup_hierarchy=false\" Update grub with sudo update-grub lab@xrdlab:~$ sudo update-grub Sourcing file `/etc/default/grub' Sourcing file `/etc/default/grub.d/init-select.cfg' Generating grub configuration file ... Found linux image: /boot/vmlinuz-5.15.0-46-generic Found initrd image: /boot/initrd.img-5.15.0-46-generic Warning: os-prober will not be executed to detect other bootable partitions. Systems on them will not be added to the GRUB boot configuration. Check GRUB_DISABLE_OS_PROBER documentation entry. done lab@xrdlab:~$ Reboot the vm sudo reboot now Increasing the max user instance echo 'fs.inotify.max_user_instances=249593' >> /etc/sysctl.conf Disable Bridge iptables, thanks to this post , the change is persitent echo 'br_netfilter' >> /etc/modules echo 'net.bridge.bridge-nf-call-iptables=1' >> /etc/sysctl.conf echo 'net.bridge.bridge-nf-call-ip6tables=1' >> /etc/sysctl.conf To update the missing CPU extensions, stop the vm and then add -cpu qemu64,+ssse3,+sse4.1,+sse4.2 in QEMU Custom options of the image in EVE-NG, but it is not applicable for the control-plane image.","title":"Fix as per the above output"},{"location":"base_setup/#host-check-again","text":"lab@xrdlab:~/github/xrd-tools/scripts$ sudo ./host-check ============================== Platform checks ============================== base checks ----------------------- PASS -- CPU architecture (x86_64) PASS -- CPU cores (16) PASS -- Kernel version (5.15) PASS -- Base kernel modules Installed module(s): dummy, nf_tables PASS -- Cgroups version (v1) PASS -- systemd mounts /sys/fs/cgroup and /sys/fs/cgroup/systemd mounted correctly. PASS -- Inotify max user instances 249593 - this is expected to be sufficient for 62 XRd instance(s). PASS -- Inotify max user watches 249593 - this is expected to be sufficient for 62 XRd instance(s). INFO -- Core pattern (core files managed by the host) PASS -- ASLR (full randomization) INFO -- Linux Security Modules AppArmor is enabled. XRd is currently unable to run with the default docker profile, but can be run with '--security-opt apparmor=unconfined' or equivalent. xrd-control-plane checks ----------------------- PASS -- RAM Available RAM is 30.7 GiB. This is estimated to be sufficient for 15 XRd instance(s), although memory usage depends on the running configuration. Note that any swap that may be available is not included. xrd-vrouter checks ----------------------- PASS -- CPU extensions (sse4_1, sse4_2, ssse3) PASS -- RAM Available RAM is 30.7 GiB. This is estimated to be sufficient for 6 XRd instance(s), although memory usage depends on the running configuration. Note that any swap that may be available is not included. FAIL -- Hugepages Hugepages are not enabled. These are required for XRd to function correctly. To enable hugepages, see the instructions at: https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt. PASS -- Interface kernel driver (vfio-pci loaded) FAIL -- IOMMU The kernel module vfio-pci cannot be used, as IOMMU is not enabled. IOMMU is recommended for security when using the vfio-pci kernel driver. PASS -- Shared memory pages max size (17179869184.0 GiB) ============================== Extra checks ============================== docker checks ----------------------- PASS -- Docker client (version 20.10.17) PASS -- Docker daemon (running, version 20.10.17) PASS -- Docker supports d_type xr-compose checks ----------------------- PASS -- docker-compose (version 1.29.2) PASS -- PyYAML (installed) PASS -- Bridge iptables (disabled) ================================================================== XR platforms supported: xrd-control-plane XR platforms NOT supported: xrd-vrouter ------------------------------------------------------------------ Extra checks passed: docker, xr-compose ================================================================== lab@xrdlab:~/github/xrd-tools/scripts$ The checks passed and the xrd-control-plane platform is now supported","title":"Host-Check again"},{"location":"base_setup/#launch-xrd","text":"Run the launch-xrd script as below to run a container from the installed image lab@xrdlab:~/github/xrd-tools/scripts$ sudo ./launch-xrd localhost/ios-xr:7.7.1 systemd 230 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP -LIBCRYPTSETUP -GCRYPT -GNUTLS +ACL +XZ -LZ4 -SECCOMP +BLKID -ELFUTILS +KMOD -IDN) Detected virtualization docker. Detected architecture x86-64. Welcome to Cisco XR (Base Distro SELinux and CGL) 9.0.0.26! Set hostname to <2382f3358d2c>. Initializing machine ID from random generator. [ OK ] Listening on Journal Socket. [ OK ] Created slice User and Session Slice. [ OK ] Reached target Paths. [ OK ] Reached target Swap. [ OK ] Reached target Remote File Systems. [ OK ] Created slice System Slice. Starting Remount Root and Kernel File Systems... Mounting Huge Pages File System... [ OK ] Reached target Slices. Mounting FUSE Control File System... Mounting Temporary Directory... [ OK ] Listening on Journal Socket (/dev/log). [ OK ] Listening on Syslog Socket. Starting Journal Service... [ OK ] Mounted Huge Pages File System. [ OK ] Mounted FUSE Control File System. [ OK ] Mounted Temporary Directory. [ OK ] Started Remount Root and Kernel File Systems. Starting Rebuild Hardware Database... Starting Load/Save Random Seed... Starting Create System Users... Starting Copy selected logs to var/log/old directories... Starting Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling... [ OK ] Started Load/Save Random Seed. [ OK ] Started Create System Users. [ OK ] Started Journal Service. Starting Flush Journal to Persistent Storage... [ OK ] Started Flush Journal to Persistent Storage. [ OK ] Started Copy selected logs to var/log/old directories. [ OK ] Started Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling. [ OK ] Reached target Local File Systems (Pre). Mounting /var/volatile... Mounting /mnt... [ OK ] Mounted /var/volatile. [ OK ] Mounted /mnt. [ OK ] Reached target Local File Systems. Starting Rebuild Journal Catalog... Starting Rebuild Dynamic Linker Cache... Starting Create Volatile Files and Directories... [ OK ] Started Rebuild Journal Catalog. [ OK ] Started Create Volatile Files and Directories. Starting Update UTMP about System Boot/Shutdown... [ OK ] Started Update UTMP about System Boot/Shutdown. [ OK ] Started Rebuild Hardware Database. [ OK ] Started Rebuild Dynamic Linker Cache. Starting Update is Completed... [ OK ] Started Update is Completed. [ OK ] Reached target System Initialization. [ OK ] Started Daily Cleanup of Temporary Directories. [ OK ] Reached target Timers. [ OK ] Listening on D-Bus System Message Bus Socket. [ OK ] Reached target Sockets. [ OK ] Reached target Basic System. Starting Resets System Activity Logs... [ OK ] Started IOS-XR XRd Core Watcher. [ OK ] Started Periodic Command Scheduler. [ OK ] Started Job spooling tools. Starting sysklogd Kernel Logging Service... Starting OpenSSH Key Generation... [ OK ] Started Service for factory reset. Starting IOS-XR Setup Non-Root related tasks... Starting System Logging Service... [ OK ] Started D-Bus System Message Bus. [ OK ] Reached target Network. Starting Permit User Sessions... Starting Xinetd A Powerful Replacement For Inetd... Starting /etc/rc.local Compatibility... [ OK ] Started Resets System Activity Logs. [ OK ] Started Permit User Sessions. [ OK ] Started /etc/rc.local Compatibility. [ OK ] Started Xinetd A Powerful Replacement For Inetd. [ OK ] Reached target Login Prompts. [ OK ] Reached target Multi-User System. Starting Update UTMP about System Runlevel Changes... [ OK ] Started Update UTMP about System Runlevel Changes. [ OK ] Started IOS-XR Setup Non-Root related tasks. [ OK ] Started OpenSSH Key Generation. Starting IOS-XR ISO Installation... [ OK ] Started System Logging Service. [ OK ] Started sysklogd Kernel Logging Service. [ 667.401907] xrnginstall[361]: 2022 Aug 20 18:41:13.106 UTC: Setting up dumper and build info files [ 667.529228] xrnginstall[361]: 2022 Aug 20 18:41:13.232 UTC: XR Lineup: r77x.lu%EFR-00000436820 [ 667.536537] xrnginstall[361]: 2022 Aug 20 18:41:13.240 UTC: XR Version: 7.7.1 [ 667.548415] xrnginstall[361]: 2022 Aug 20 18:41:13.252 UTC: Completed set up of dumper and build info files [ 667.557122] xrnginstall[361]: 2022 Aug 20 18:41:13.261 UTC: Preparing IOS-XR (first boot) [ 667.724285] xrnginstall[361]: 2022 Aug 20 18:41:13.427 UTC: Checking if rollback cleanup is required [ 667.733597] xrnginstall[361]: 2022 Aug 20 18:41:13.436 UTC: Finished rollback cleanup stage [ 667.740465] xrnginstall[361]: 2022 Aug 20 18:41:13.443 UTC: Single node: starting XR [ 667.757563] xrnginstall[361]: 2022 Aug 20 18:41:13.461 UTC: xrnginstall completed successfully [ OK ] Started IOS-XR ISO Installation. Starting IOS-XR XRd... [ OK ] Started Cisco Directory Services. [ OK ] Started IOS-XR XRd. Starting IOS-XR Reaperd and Process Manager... [ OK ] Started IOS-XR Reaperd and Process Manager. [ OK ] Reached target XR installation and startup. ios con0/RP0/CPU0 is now available Press RETURN to get started. This product contains cryptographic features and is subject to United States and local country laws governing import, export, transfer and use. Delivery of Cisco cryptographic products does not imply third-party authority to import, export, distribute or use encryption. Importers, exporters, distributors and users are responsible for compliance with U.S. and local country laws. By using this product you agree to comply with applicable laws and regulations. If you are unable to comply with U.S. and local laws, return this product immediately. A summary of U.S. laws governing Cisco cryptographic products may be found at: http://www.cisco.com/wwl/export/crypto/tool/stqrg.html If you require further assistance please contact us by sending email to export@cisco.com. RP/0/RP0/CPU0:Aug 20 18:41:24.932 UTC: pyztp2[252]: %INFRA-ZTP-4-EXITED : ZTP exited !!!!!!!!!!!!!!!!!!!! NO root-system username is configured. Need to configure root-system username. !!!!!!!!!!!!!!!!!!!! --- Administrative User Dialog --- Enter root-system username: RP/0/RP0/CPU0:Aug 20 18:41:28.381 UTC: smartlicserver[266]: %LICENSE-SMART_LIC-3-COMM_FAILED : Communications failure with the Cisco Smart Software Manager (CSSM) : Communications init failure co % Entry must not be null. Enter root-system username: cisco Enter secret: Enter secret again: Use the 'configure' command to modify this configuration. User Access Verification Username: cisco Password: RP/0/RP0/CPU0:ios#show platform Sat Aug 20 18:41:45.892 UTC Node Type State Config state -------------------------------------------------------------------------------- 0/RP0/CPU0 XRd-CP-C-01(Active) IOS XR RUN NSHUT RP/0/RP0/CPU0:ios#show version RP/0/RP0/CPU0:ios# Sat Aug 20 18:41:48.353 UTC Cisco IOS XR Software, Version 7.7.1 LNT Copyright (c) 2013-2022 by Cisco Systems, Inc. Build Information: Built By : ingunawa Built On : Mon Jul 25 06:07:25 UTC 2022 Build Host : iox-lnx-121 Workspace : /auto/srcarchive12/prod/7.7.1/xrd-control-plane/ws Version : 7.7.1 Label : 7.7.1 cisco XRd Control Plane cisco XRd-CP-C-01 processor with 32GB of memory ios uptime is 0 minutes XRd Control Plane Container RP/0/RP0/CPU0:ios#sh int brief Sat Aug 20 18:41:56.784 UTC Intf Intf LineP Encap MTU BW Name State State Type (byte) (Kbps) -------------------------------------------------------------------------------- Nu0 up up Null 1500 0 Mg0/RP0/CPU0/0 admin-down admin-down ARPA 1514 1000000 RP/0/RP0/CPU0:ios# I couldn't get out of the docker container, so I had to stop the container by opening another terminal session to the vm.","title":"Launch XRd"},{"location":"base_setup/#it-works","text":"","title":"It works!"},{"location":"base_setup/#thank-you","text":"","title":"Thank You!"},{"location":"segment_routing/","text":"Segment Routing Topology and IP addresses as per the repo xrd-7(PCE) / \\ xrd-3 --- xrd-4 / | | \\ src --- xrd-1 | | xrd-2 --- dst \\ | | / xrd-5 --- xrd-6 \\ / xrd-8(vRR) IP addresses source: 10.1.1.2 xrd-1-GE2 (left ): 10.1.1.3 xrd-2-GE2 (right): 10.3.1.2 dest: 10.3.1.3 XR-Compose Run the xr-compose script to generate the docker-compose.yml from the docker-compose.xr.yml lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo ~/xr-compose -i localhost/ios-xr:7.7.1 INFO - Writing output docker-compose YAML to docker-compose.yml lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ Note: I copied the xrd-tools scripts in the home directory Launch Topology Launch the topology with docker-compose lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker-compose up -d Creating network \"segment-routing_xrd-2-dest\" with the default driver Creating network \"segment-routing_source-xrd-1\" with the default driver Creating network \"segment-routing_mgmt\" with the default driver Creating network \"xrd-1-gi0-xrd-3-gi2\" with the default driver Creating network \"xrd-1-gi1-xrd-5-gi2\" with the default driver Creating network \"xrd-2-gi0-xrd-4-gi2\" with the default driver Creating network \"xrd-2-gi1-xrd-6-gi2\" with the default driver Creating network \"xrd-3-gi0-xrd-4-gi0\" with the default driver Creating network \"xrd-3-gi1-xrd-5-gi1\" with the default driver Creating network \"xrd-3-gi3-xrd-7-gi0\" with the default driver Creating network \"xrd-4-gi1-xrd-6-gi1\" with the default driver Creating network \"xrd-4-gi3-xrd-7-gi1\" with the default driver Creating network \"xrd-5-gi0-xrd-6-gi0\" with the default driver Creating network \"xrd-5-gi3-xrd-8-gi0\" with the default driver Creating network \"xrd-6-gi3-xrd-8-gi1\" with the default driver Creating volume \"xrd-1\" with default driver Creating volume \"xrd-2\" with default driver Creating volume \"xrd-3\" with default driver Creating volume \"xrd-4\" with default driver Creating volume \"xrd-5\" with default driver Creating volume \"xrd-6\" with default driver Creating volume \"xrd-7\" with default driver Creating volume \"xrd-8\" with default driver Creating xrd-7 ... done Creating xrd-5 ... done Creating xrd-4 ... done Creating xrd-8 ... done Creating source ... done Creating xrd-3 ... done Creating xrd-1 ... done Creating xrd-2 ... done Creating xrd-6 ... done Creating dest ... done lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ Give it another 3 to 4 minutes for the topology to become ready and all the protocols to converge to establish end to end connectivty. Containers lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1cde11703e27 alpine:3.15 \"/bin/sh -c 'ip rout\u2026\" About a minute ago Up About a minute dest 9fc07e38d183 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-1 2e24e776c2c3 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-2 ee5543a989d3 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-6 d3313d61ad20 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-4 5a1a4f85aa4f localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-3 63605a31c730 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-8 8a58dc7a2b52 alpine:3.15 \"/bin/sh -c 'ip rout\u2026\" About a minute ago Up About a minute source 5857e851579c localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-7 e895f5dffb1b localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-5 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ Container Networks lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker network ls NETWORK ID NAME DRIVER SCOPE 6e695b3d51ed bridge bridge local 3fa096a64551 host host local 98eac983e612 none null local f77fc08c8ad3 segment-routing_mgmt bridge local 47546614c0f5 segment-routing_source-xrd-1 bridge local 7122494bf9c0 segment-routing_xrd-2-dest bridge local 43b203d3505f xrd-1-gi0-xrd-3-gi2 bridge local 9c4b04abad23 xrd-1-gi1-xrd-5-gi2 bridge local 843d61caa800 xrd-2-gi0-xrd-4-gi2 bridge local f6406a95c2d1 xrd-2-gi1-xrd-6-gi2 bridge local 6ee4c5354bd5 xrd-3-gi0-xrd-4-gi0 bridge local 9cd5784fcfff xrd-3-gi1-xrd-5-gi1 bridge local a85d98350feb xrd-3-gi3-xrd-7-gi0 bridge local 4ffa878ef578 xrd-4-gi1-xrd-6-gi1 bridge local 2e3c61a683c9 xrd-4-gi3-xrd-7-gi1 bridge local b271075062d5 xrd-5-gi0-xrd-6-gi0 bridge local eba72e670769 xrd-5-gi3-xrd-8-gi0 bridge local 86805bf51a09 xrd-6-gi3-xrd-8-gi1 bridge local lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ End to End Network Reachability As per the docker-compose comments, The IP on source is 10.1.1.2 and on dest is 10.3.1.3 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker exec source traceroute 10.3.1.3 traceroute to 10.3.1.3 (10.3.1.3), 30 hops max, 46 byte packets 1 xrd-1.segment-routing_source-xrd-1 (10.1.1.3) 8.898 ms 1.140 ms 0.974 ms 2 100.101.103.103 (100.101.103.103) 11.935 ms 6.642 ms 6.495 ms 3 100.103.104.104 (100.103.104.104) 9.953 ms 6.934 ms 6.743 ms 4 100.102.104.102 (100.102.104.102) 8.341 ms 5.984 ms 6.157 ms 5 10.3.1.3 (10.3.1.3) 11.020 ms 7.204 ms 7.406 ms lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ Shutdown Topology lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker-compose down Stopping dest ... done Stopping xrd-1 ... done Stopping xrd-2 ... done Stopping xrd-6 ... done Stopping xrd-4 ... done Stopping xrd-3 ... done Stopping xrd-8 ... done Stopping source ... done Stopping xrd-7 ... done Stopping xrd-5 ... done Removing dest ... done Removing xrd-1 ... done Removing xrd-2 ... done Removing xrd-6 ... done Removing xrd-4 ... done Removing xrd-3 ... done Removing xrd-8 ... done Removing source ... done Removing xrd-7 ... done Removing xrd-5 ... done Removing network segment-routing_xrd-2-dest Removing network segment-routing_source-xrd-1 Removing network segment-routing_mgmt Removing network xrd-1-gi0-xrd-3-gi2 Removing network xrd-1-gi1-xrd-5-gi2 Removing network xrd-2-gi0-xrd-4-gi2 Removing network xrd-2-gi1-xrd-6-gi2 Removing network xrd-3-gi0-xrd-4-gi0 Removing network xrd-3-gi1-xrd-5-gi1 Removing network xrd-3-gi3-xrd-7-gi0 Removing network xrd-4-gi1-xrd-6-gi1 Removing network xrd-4-gi3-xrd-7-gi1 Removing network xrd-5-gi0-xrd-6-gi0 Removing network xrd-5-gi3-xrd-8-gi0 Removing network xrd-6-gi3-xrd-8-gi1 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ After Some time, I will take another look at the XRd outputs. So far, it is very promising! Thank You","title":"Segment Routing"},{"location":"segment_routing/#segment-routing","text":"Topology and IP addresses as per the repo xrd-7(PCE) / \\ xrd-3 --- xrd-4 / | | \\ src --- xrd-1 | | xrd-2 --- dst \\ | | / xrd-5 --- xrd-6 \\ / xrd-8(vRR) IP addresses source: 10.1.1.2 xrd-1-GE2 (left ): 10.1.1.3 xrd-2-GE2 (right): 10.3.1.2 dest: 10.3.1.3","title":"Segment Routing"},{"location":"segment_routing/#xr-compose","text":"Run the xr-compose script to generate the docker-compose.yml from the docker-compose.xr.yml lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo ~/xr-compose -i localhost/ios-xr:7.7.1 INFO - Writing output docker-compose YAML to docker-compose.yml lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ Note: I copied the xrd-tools scripts in the home directory","title":"XR-Compose"},{"location":"segment_routing/#launch-topology","text":"Launch the topology with docker-compose lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker-compose up -d Creating network \"segment-routing_xrd-2-dest\" with the default driver Creating network \"segment-routing_source-xrd-1\" with the default driver Creating network \"segment-routing_mgmt\" with the default driver Creating network \"xrd-1-gi0-xrd-3-gi2\" with the default driver Creating network \"xrd-1-gi1-xrd-5-gi2\" with the default driver Creating network \"xrd-2-gi0-xrd-4-gi2\" with the default driver Creating network \"xrd-2-gi1-xrd-6-gi2\" with the default driver Creating network \"xrd-3-gi0-xrd-4-gi0\" with the default driver Creating network \"xrd-3-gi1-xrd-5-gi1\" with the default driver Creating network \"xrd-3-gi3-xrd-7-gi0\" with the default driver Creating network \"xrd-4-gi1-xrd-6-gi1\" with the default driver Creating network \"xrd-4-gi3-xrd-7-gi1\" with the default driver Creating network \"xrd-5-gi0-xrd-6-gi0\" with the default driver Creating network \"xrd-5-gi3-xrd-8-gi0\" with the default driver Creating network \"xrd-6-gi3-xrd-8-gi1\" with the default driver Creating volume \"xrd-1\" with default driver Creating volume \"xrd-2\" with default driver Creating volume \"xrd-3\" with default driver Creating volume \"xrd-4\" with default driver Creating volume \"xrd-5\" with default driver Creating volume \"xrd-6\" with default driver Creating volume \"xrd-7\" with default driver Creating volume \"xrd-8\" with default driver Creating xrd-7 ... done Creating xrd-5 ... done Creating xrd-4 ... done Creating xrd-8 ... done Creating source ... done Creating xrd-3 ... done Creating xrd-1 ... done Creating xrd-2 ... done Creating xrd-6 ... done Creating dest ... done lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ Give it another 3 to 4 minutes for the topology to become ready and all the protocols to converge to establish end to end connectivty.","title":"Launch Topology"},{"location":"segment_routing/#containers","text":"lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1cde11703e27 alpine:3.15 \"/bin/sh -c 'ip rout\u2026\" About a minute ago Up About a minute dest 9fc07e38d183 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-1 2e24e776c2c3 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-2 ee5543a989d3 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-6 d3313d61ad20 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-4 5a1a4f85aa4f localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-3 63605a31c730 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-8 8a58dc7a2b52 alpine:3.15 \"/bin/sh -c 'ip rout\u2026\" About a minute ago Up About a minute source 5857e851579c localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-7 e895f5dffb1b localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xrd-5 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$","title":"Containers"},{"location":"segment_routing/#container-networks","text":"lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker network ls NETWORK ID NAME DRIVER SCOPE 6e695b3d51ed bridge bridge local 3fa096a64551 host host local 98eac983e612 none null local f77fc08c8ad3 segment-routing_mgmt bridge local 47546614c0f5 segment-routing_source-xrd-1 bridge local 7122494bf9c0 segment-routing_xrd-2-dest bridge local 43b203d3505f xrd-1-gi0-xrd-3-gi2 bridge local 9c4b04abad23 xrd-1-gi1-xrd-5-gi2 bridge local 843d61caa800 xrd-2-gi0-xrd-4-gi2 bridge local f6406a95c2d1 xrd-2-gi1-xrd-6-gi2 bridge local 6ee4c5354bd5 xrd-3-gi0-xrd-4-gi0 bridge local 9cd5784fcfff xrd-3-gi1-xrd-5-gi1 bridge local a85d98350feb xrd-3-gi3-xrd-7-gi0 bridge local 4ffa878ef578 xrd-4-gi1-xrd-6-gi1 bridge local 2e3c61a683c9 xrd-4-gi3-xrd-7-gi1 bridge local b271075062d5 xrd-5-gi0-xrd-6-gi0 bridge local eba72e670769 xrd-5-gi3-xrd-8-gi0 bridge local 86805bf51a09 xrd-6-gi3-xrd-8-gi1 bridge local lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$","title":"Container Networks"},{"location":"segment_routing/#end-to-end-network-reachability","text":"As per the docker-compose comments, The IP on source is 10.1.1.2 and on dest is 10.3.1.3 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker exec source traceroute 10.3.1.3 traceroute to 10.3.1.3 (10.3.1.3), 30 hops max, 46 byte packets 1 xrd-1.segment-routing_source-xrd-1 (10.1.1.3) 8.898 ms 1.140 ms 0.974 ms 2 100.101.103.103 (100.101.103.103) 11.935 ms 6.642 ms 6.495 ms 3 100.103.104.104 (100.103.104.104) 9.953 ms 6.934 ms 6.743 ms 4 100.102.104.102 (100.102.104.102) 8.341 ms 5.984 ms 6.157 ms 5 10.3.1.3 (10.3.1.3) 11.020 ms 7.204 ms 7.406 ms lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$","title":"End to End Network Reachability"},{"location":"segment_routing/#shutdown-topology","text":"lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ sudo docker-compose down Stopping dest ... done Stopping xrd-1 ... done Stopping xrd-2 ... done Stopping xrd-6 ... done Stopping xrd-4 ... done Stopping xrd-3 ... done Stopping xrd-8 ... done Stopping source ... done Stopping xrd-7 ... done Stopping xrd-5 ... done Removing dest ... done Removing xrd-1 ... done Removing xrd-2 ... done Removing xrd-6 ... done Removing xrd-4 ... done Removing xrd-3 ... done Removing xrd-8 ... done Removing source ... done Removing xrd-7 ... done Removing xrd-5 ... done Removing network segment-routing_xrd-2-dest Removing network segment-routing_source-xrd-1 Removing network segment-routing_mgmt Removing network xrd-1-gi0-xrd-3-gi2 Removing network xrd-1-gi1-xrd-5-gi2 Removing network xrd-2-gi0-xrd-4-gi2 Removing network xrd-2-gi1-xrd-6-gi2 Removing network xrd-3-gi0-xrd-4-gi0 Removing network xrd-3-gi1-xrd-5-gi1 Removing network xrd-3-gi3-xrd-7-gi0 Removing network xrd-4-gi1-xrd-6-gi1 Removing network xrd-4-gi3-xrd-7-gi1 Removing network xrd-5-gi0-xrd-6-gi0 Removing network xrd-5-gi3-xrd-8-gi0 Removing network xrd-6-gi3-xrd-8-gi1 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/segment-routing$ After Some time, I will take another look at the XRd outputs. So far, it is very promising!","title":"Shutdown Topology"},{"location":"segment_routing/#thank-you","text":"","title":"Thank You"},{"location":"simple_bgp/","text":"Simple BGP Topology as per the repo source <--> xr-1 <--> xr-2 <--> dest XR-Compose Run the xr-compose script to generate the docker-compose.yml from the docker-compose.xr.yml lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo ~/xr-compose -i localhost/ios-xr:7.7.1 INFO - Writing output docker-compose YAML to docker-compose.yml lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ Note: I copied the xrd-tools scripts in the home directory Launch Topology Launch the topology with docker-compose lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker-compose up -d Creating network \"simple-bgp_xrd-2-dest\" with the default driver Creating network \"simple-bgp_source-xrd-1\" with the default driver Creating network \"simple-bgp_mgmt\" with the default driver Creating network \"xr-1-gi1-xr-2-gi0\" with the default driver Creating volume \"xr-1\" with default driver Creating volume \"xr-2\" with default driver Pulling dest (alpine:3.15)... 3.15: Pulling from library/alpine 9621f1afde84: Pull complete Digest: sha256:69463fdff1f025c908939e86d4714b4d5518776954ca627cbeff4c74bcea5b22 Status: Downloaded newer image for alpine:3.15 Creating xr-2 ... done Creating xr-1 ... done Creating dest ... done Creating source ... done lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ The docker compose file uses an alpine:3.15 docker image to emulate as hosts, which is pulled from the docker repository when used for the first time Containers lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d9c64d9342f4 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xr-1 c06ada3e07b1 alpine:3.15 \"/bin/sh -c 'ip rout\u2026\" About a minute ago Up About a minute source 5a7981d7fde3 alpine:3.15 \"/bin/sh -c 'ip rout\u2026\" About a minute ago Up About a minute dest 96ae55e77f82 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xr-2 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ Container Networks lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker network ls NETWORK ID NAME DRIVER SCOPE 6e695b3d51ed bridge bridge local 3fa096a64551 host host local 98eac983e612 none null local 916aed1cab06 simple-bgp_mgmt bridge local 569004635c3f simple-bgp_source-xrd-1 bridge local 57eb8370acc0 simple-bgp_xrd-2-dest bridge local 5749aabe0b90 xr-1-gi1-xr-2-gi0 bridge local lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ End to End Network Reachability As per the docker-compose comments, The IP on source is 10.1.1.2 and on dest is 10.3.1.3 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker exec source traceroute 10.3.1.3 traceroute to 10.3.1.3 (10.3.1.3), 30 hops max, 46 byte packets 1 xr-1.simple-bgp_source-xrd-1 (10.1.1.3) 1.585 ms 1.090 ms 0.857 ms 2 10.2.1.3 (10.2.1.3) 2.722 ms 2.814 ms 2.174 ms 3 10.3.1.3 (10.3.1.3) 2.377 ms 2.797 ms 2.457 ms lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ Cisco XRd Checks I couldn't find an easier way to login to the docker containers running XRd, other than using docker attach as below, used ctrl-\\ as escape character to detach from the container lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker attach --detach-keys=ctrl-\\\\ xr-1 !!!!!!!!!!!!!!!!!!!! NO root-system username is configured. Need to configure root-system username. !!!!!!!!!!!!!!!!!!!! --- Administrative User Dialog --- Enter root-system username: cisco Enter secret: Enter secret again: Use the 'configure' command to modify this configuration. User Access Verification Username: cisco Password: RP/0/RP0/CPU0:ios#sh route Sat Aug 20 19:46:12.151 UTC Codes: C - connected, S - static, R - RIP, B - BGP, (>) - Diversion path D - EIGRP, EX - EIGRP external, O - OSPF, IA - OSPF inter area N1 - OSPF NSSA external type 1, N2 - OSPF NSSA external type 2 E1 - OSPF external type 1, E2 - OSPF external type 2, E - EGP i - ISIS, L1 - IS-IS level-1, L2 - IS-IS level-2 ia - IS-IS inter area, su - IS-IS summary null, * - candidate default U - per-user static route, o - ODR, L - local, G - DAGR, l - LISP A - access/subscriber, a - Application route M - mobile route, r - RPL, t - Traffic Engineering, (!) - FRR Backup path Gateway of last resort is not set C 10.1.1.0/24 is directly connected, 00:01:24, GigabitEthernet0/0/0/0 L 10.1.1.3/32 is directly connected, 00:01:24, GigabitEthernet0/0/0/0 C 10.2.1.0/24 is directly connected, 00:01:24, GigabitEthernet0/0/0/1 L 10.2.1.2/32 is directly connected, 00:01:24, GigabitEthernet0/0/0/1 B 10.3.1.0/24 [200/0] via 10.2.1.3, 00:00:46 C 172.30.0.0/24 is directly connected, 00:01:24, MgmtEth0/RP0/CPU0/0 L 172.30.0.2/32 is directly connected, 00:01:24, MgmtEth0/RP0/CPU0/0 RP/0/RP0/CPU0:ios#sh bgp summary Sat Aug 20 19:46:14.642 UTC BGP router identifier 10.2.1.2, local AS number 100 BGP generic scan interval 60 secs Non-stop routing is enabled BGP table state: Active Table ID: 0xe0000000 RD version: 9 BGP main routing table version 9 BGP NSR Initial initsync version 5 (Reached) BGP NSR/ISSU Sync-Group versions 0/0 BGP scan interval 60 secs BGP is operating in STANDALONE mode. Process RcvTblVer bRIB/RIB LabelVer ImportVer SendTblVer StandbyVer Speaker 9 9 9 9 9 0 Neighbor Spk AS MsgRcvd MsgSent TblVer InQ OutQ Up/Down St/PfxRcd 10.2.1.3 0 100 4 4 9 0 0 00:00:54 3 RP/0/RP0/CPU0:ios#sh bgp neighbor 10.2.1.3 routes Sat Aug 20 19:46:20.202 UTC BGP router identifier 10.2.1.2, local AS number 100 BGP generic scan interval 60 secs Non-stop routing is enabled BGP table state: Active Table ID: 0xe0000000 RD version: 9 BGP main routing table version 9 BGP NSR Initial initsync version 5 (Reached) BGP NSR/ISSU Sync-Group versions 0/0 BGP scan interval 60 secs Status codes: s suppressed, d damped, h history, * valid, > best i - internal, r RIB-failure, S stale, N Nexthop-discard Origin codes: i - IGP, e - EGP, ? - incomplete Network Next Hop Metric LocPrf Weight Path * i10.2.1.0/24 10.2.1.3 0 100 0 ? *>i10.3.1.0/24 10.2.1.3 0 100 0 ? * i172.30.0.0/24 10.2.1.3 0 100 0 ? Processed 3 prefixes, 3 paths RP/0/RP0/CPU0:ios#sh bgp neighbor 10.2.1.3 advertised-routes Sat Aug 20 19:46:23.621 UTC Network Next Hop From AS Path 10.1.1.0/24 10.2.1.2 Local ? 10.2.1.0/24 10.2.1.2 Local ? 172.30.0.0/24 10.2.1.2 Local ? Processed 3 prefixes, 3 paths RP/0/RP0/CPU0:ios#read escape sequence lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ Shutdown Topology lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker-compose down Stopping xr-1 ... done Stopping source ... done Stopping dest ... done Stopping xr-2 ... done Removing xr-1 ... done Removing source ... done Removing dest ... done Removing xr-2 ... done Removing network simple-bgp_xrd-2-dest Removing network simple-bgp_source-xrd-1 Removing network simple-bgp_mgmt Removing network xr-1-gi1-xr-2-gi0 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ Thank You","title":"Simple BGP"},{"location":"simple_bgp/#simple-bgp","text":"Topology as per the repo source <--> xr-1 <--> xr-2 <--> dest","title":"Simple BGP"},{"location":"simple_bgp/#xr-compose","text":"Run the xr-compose script to generate the docker-compose.yml from the docker-compose.xr.yml lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo ~/xr-compose -i localhost/ios-xr:7.7.1 INFO - Writing output docker-compose YAML to docker-compose.yml lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ Note: I copied the xrd-tools scripts in the home directory","title":"XR-Compose"},{"location":"simple_bgp/#launch-topology","text":"Launch the topology with docker-compose lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker-compose up -d Creating network \"simple-bgp_xrd-2-dest\" with the default driver Creating network \"simple-bgp_source-xrd-1\" with the default driver Creating network \"simple-bgp_mgmt\" with the default driver Creating network \"xr-1-gi1-xr-2-gi0\" with the default driver Creating volume \"xr-1\" with default driver Creating volume \"xr-2\" with default driver Pulling dest (alpine:3.15)... 3.15: Pulling from library/alpine 9621f1afde84: Pull complete Digest: sha256:69463fdff1f025c908939e86d4714b4d5518776954ca627cbeff4c74bcea5b22 Status: Downloaded newer image for alpine:3.15 Creating xr-2 ... done Creating xr-1 ... done Creating dest ... done Creating source ... done lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ The docker compose file uses an alpine:3.15 docker image to emulate as hosts, which is pulled from the docker repository when used for the first time","title":"Launch Topology"},{"location":"simple_bgp/#containers","text":"lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d9c64d9342f4 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xr-1 c06ada3e07b1 alpine:3.15 \"/bin/sh -c 'ip rout\u2026\" About a minute ago Up About a minute source 5a7981d7fde3 alpine:3.15 \"/bin/sh -c 'ip rout\u2026\" About a minute ago Up About a minute dest 96ae55e77f82 localhost/ios-xr:7.7.1 \"/bin/sh -c /sbin/xr\u2026\" About a minute ago Up About a minute xr-2 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$","title":"Containers"},{"location":"simple_bgp/#container-networks","text":"lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker network ls NETWORK ID NAME DRIVER SCOPE 6e695b3d51ed bridge bridge local 3fa096a64551 host host local 98eac983e612 none null local 916aed1cab06 simple-bgp_mgmt bridge local 569004635c3f simple-bgp_source-xrd-1 bridge local 57eb8370acc0 simple-bgp_xrd-2-dest bridge local 5749aabe0b90 xr-1-gi1-xr-2-gi0 bridge local lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$","title":"Container Networks"},{"location":"simple_bgp/#end-to-end-network-reachability","text":"As per the docker-compose comments, The IP on source is 10.1.1.2 and on dest is 10.3.1.3 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker exec source traceroute 10.3.1.3 traceroute to 10.3.1.3 (10.3.1.3), 30 hops max, 46 byte packets 1 xr-1.simple-bgp_source-xrd-1 (10.1.1.3) 1.585 ms 1.090 ms 0.857 ms 2 10.2.1.3 (10.2.1.3) 2.722 ms 2.814 ms 2.174 ms 3 10.3.1.3 (10.3.1.3) 2.377 ms 2.797 ms 2.457 ms lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$","title":"End to End Network Reachability"},{"location":"simple_bgp/#cisco-xrd-checks","text":"I couldn't find an easier way to login to the docker containers running XRd, other than using docker attach as below, used ctrl-\\ as escape character to detach from the container lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker attach --detach-keys=ctrl-\\\\ xr-1 !!!!!!!!!!!!!!!!!!!! NO root-system username is configured. Need to configure root-system username. !!!!!!!!!!!!!!!!!!!! --- Administrative User Dialog --- Enter root-system username: cisco Enter secret: Enter secret again: Use the 'configure' command to modify this configuration. User Access Verification Username: cisco Password: RP/0/RP0/CPU0:ios#sh route Sat Aug 20 19:46:12.151 UTC Codes: C - connected, S - static, R - RIP, B - BGP, (>) - Diversion path D - EIGRP, EX - EIGRP external, O - OSPF, IA - OSPF inter area N1 - OSPF NSSA external type 1, N2 - OSPF NSSA external type 2 E1 - OSPF external type 1, E2 - OSPF external type 2, E - EGP i - ISIS, L1 - IS-IS level-1, L2 - IS-IS level-2 ia - IS-IS inter area, su - IS-IS summary null, * - candidate default U - per-user static route, o - ODR, L - local, G - DAGR, l - LISP A - access/subscriber, a - Application route M - mobile route, r - RPL, t - Traffic Engineering, (!) - FRR Backup path Gateway of last resort is not set C 10.1.1.0/24 is directly connected, 00:01:24, GigabitEthernet0/0/0/0 L 10.1.1.3/32 is directly connected, 00:01:24, GigabitEthernet0/0/0/0 C 10.2.1.0/24 is directly connected, 00:01:24, GigabitEthernet0/0/0/1 L 10.2.1.2/32 is directly connected, 00:01:24, GigabitEthernet0/0/0/1 B 10.3.1.0/24 [200/0] via 10.2.1.3, 00:00:46 C 172.30.0.0/24 is directly connected, 00:01:24, MgmtEth0/RP0/CPU0/0 L 172.30.0.2/32 is directly connected, 00:01:24, MgmtEth0/RP0/CPU0/0 RP/0/RP0/CPU0:ios#sh bgp summary Sat Aug 20 19:46:14.642 UTC BGP router identifier 10.2.1.2, local AS number 100 BGP generic scan interval 60 secs Non-stop routing is enabled BGP table state: Active Table ID: 0xe0000000 RD version: 9 BGP main routing table version 9 BGP NSR Initial initsync version 5 (Reached) BGP NSR/ISSU Sync-Group versions 0/0 BGP scan interval 60 secs BGP is operating in STANDALONE mode. Process RcvTblVer bRIB/RIB LabelVer ImportVer SendTblVer StandbyVer Speaker 9 9 9 9 9 0 Neighbor Spk AS MsgRcvd MsgSent TblVer InQ OutQ Up/Down St/PfxRcd 10.2.1.3 0 100 4 4 9 0 0 00:00:54 3 RP/0/RP0/CPU0:ios#sh bgp neighbor 10.2.1.3 routes Sat Aug 20 19:46:20.202 UTC BGP router identifier 10.2.1.2, local AS number 100 BGP generic scan interval 60 secs Non-stop routing is enabled BGP table state: Active Table ID: 0xe0000000 RD version: 9 BGP main routing table version 9 BGP NSR Initial initsync version 5 (Reached) BGP NSR/ISSU Sync-Group versions 0/0 BGP scan interval 60 secs Status codes: s suppressed, d damped, h history, * valid, > best i - internal, r RIB-failure, S stale, N Nexthop-discard Origin codes: i - IGP, e - EGP, ? - incomplete Network Next Hop Metric LocPrf Weight Path * i10.2.1.0/24 10.2.1.3 0 100 0 ? *>i10.3.1.0/24 10.2.1.3 0 100 0 ? * i172.30.0.0/24 10.2.1.3 0 100 0 ? Processed 3 prefixes, 3 paths RP/0/RP0/CPU0:ios#sh bgp neighbor 10.2.1.3 advertised-routes Sat Aug 20 19:46:23.621 UTC Network Next Hop From AS Path 10.1.1.0/24 10.2.1.2 Local ? 10.2.1.0/24 10.2.1.2 Local ? 172.30.0.0/24 10.2.1.2 Local ? Processed 3 prefixes, 3 paths RP/0/RP0/CPU0:ios#read escape sequence lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$","title":"Cisco XRd Checks"},{"location":"simple_bgp/#shutdown-topology","text":"lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$ sudo docker-compose down Stopping xr-1 ... done Stopping source ... done Stopping dest ... done Stopping xr-2 ... done Removing xr-1 ... done Removing source ... done Removing dest ... done Removing xr-2 ... done Removing network simple-bgp_xrd-2-dest Removing network simple-bgp_source-xrd-1 Removing network simple-bgp_mgmt Removing network xr-1-gi1-xr-2-gi0 lab@xrdlab:~/github/xrd-tools/samples/xr_compose_topos/simple-bgp$","title":"Shutdown Topology"},{"location":"simple_bgp/#thank-you","text":"","title":"Thank You"}]}